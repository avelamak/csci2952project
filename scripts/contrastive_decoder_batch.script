#!/bin/bash

# This is an example batch script for slurm on Oscar
#
# The commands for slurm start with #SBATCH
# All slurm commands need to come before the program
# you want to run.  In this example, 'echo "Hello World!"
# is the command we are running.
#
# This is a bash script, so any line that starts with # is
# a comment.  If you need to comment out an #SBATCH line
# use ##SBATCH
#
# To submit this script to slurm do:
#    sbatch batch.script
#
# Once the job starts you will see a file MySerialJob-****.out
# The **** will be the slurm JobID

# --- Start of slurm commands -----------

#SBATCH --time=48:00:00

#SBATCH --mem=128G
#SBATCH --cpus-per-task=12
#SBATCH --partition=gpu
#SBATCH --gres=gpu:2
#SBATCH --nodes=1

#SBATCH -J Contrastive
#SBATCH -o Contrastive-%j.out
#SBATCH -e Contrastive-%j.err

#----- End of slurm commands ----


source .venv/bin/activate
wandb login

accelerate launch --num_processes=2 scripts/train_decoder_from_contrastive.py \
    --contrastive-checkpoint /oscar/scratch/zzhan215/exps/contrastive/best_model.pt \
    --svg-dir /oscar/scratch/zzhan215/google_fonts_processed_reduced/svg/ \
    --img-dir /oscar/scratch/zzhan215/google_fonts_processed_reduced/img/ \
    --meta /oscar/scratch/zzhan215/google_fonts_processed_reduced/metadata.csv \
    --batch-size 128 \
    --epoch 100 \
    --lr 1e-4 \
    --num-workers 0 \
    --wandb-project vecssl_contrastive_decoder \
    --wandb-name contrastive_decoder \
    --wandb-entity vecssl \
    --checkpoint-dir ./checkpoints/contrastive_decoder \
    --log-every 1 \
    --save-every 1 \
    --resume-from ./checkpoints/contrastive_decoder/best_model.pt
